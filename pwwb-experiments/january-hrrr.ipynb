{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "deca3910-8b85-4d35-ba11-4278b6cfa502",
   "metadata": {},
   "source": [
    "# Experiment 4: Fire January set + HRRR\n",
    "\n",
    "This notebook focuses on running Experiment 4, which uses data from January (fire period) combining PWWB, AirNow, and HRRR datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c92945-842a-4338-9ec2-a954bca054a8",
   "metadata": {},
   "source": [
    "# Data parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a247a5-a0e5-46f7-adbd-3234c2f952d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define bounding box\n",
    "lat_bottom, lat_top = 33.9, 34.2\n",
    "lon_bottom, lon_top = -118.4, -118.0\n",
    "extent = (lon_bottom, lon_top, lat_bottom, lat_top)\n",
    "\n",
    "# input data shape\n",
    "dim = 200\n",
    "frames_per_sample = 5\n",
    "\n",
    "# date range of data - January only for this experiment\n",
    "jan_start_date, jan_end_date = \"2025-01-16-00\", \"2025-01-23-00\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a17cf45-39ee-4320-a2b6-93bf9c095667",
   "metadata": {},
   "source": [
    "# Data ingestion and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cd894d-b165-4b11-9d41-0608bdf6783e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python nonsense that allows you to import from sibling directories\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Import the data classes\n",
    "from libs.pwwbdata import PWWBData\n",
    "from libs.airnowdata import AirNowData\n",
    "from libs.hrrrdata import HRRRData\n",
    "\n",
    "# Load environment variables (API keys, credentials)\n",
    "load_dotenv()\n",
    "\n",
    "# split data\n",
    "def train_test_split(X, train_size=0.75):\n",
    "    split_idx = int(X.shape[0] * train_size)\n",
    "    X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "    \n",
    "    return X_train, X_test\n",
    "\n",
    "# scale training data, then scale test data based on training data stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "def std_scale(X_train, X_test):\n",
    "    scaler = StandardScaler()\n",
    "    scaled_train = scaler.fit_transform(X_train.reshape(-1, 1)).reshape(X_train.shape)\n",
    "    scaled_test = scaler.transform(X_test.reshape(-1, 1)).reshape(X_test.shape)\n",
    "\n",
    "    return scaled_train, scaled_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "process_jan_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory for results\n",
    "output_dir = \"experiment_output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "jan_end_date_adj = pd.to_datetime(jan_end_date) - pd.Timedelta(hours=1)\n",
    "\n",
    "# ========== 1. Load January PWWB Data ==========\n",
    "print(\"\\nLoading January PWWB data...\")\n",
    "jan_pwwb = PWWBData(\n",
    "    start_date=jan_start_date,\n",
    "    end_date=jan_end_date,\n",
    "    extent=extent,\n",
    "    frames_per_sample=frames_per_sample,\n",
    "    dim=dim,\n",
    "    env_file='.env',\n",
    "    verbose=True,\n",
    "    output_dir=output_dir\n",
    ")\n",
    "X_jan_pwwb = jan_pwwb.data\n",
    "channel_info = jan_pwwb.get_channel_info()\n",
    "print(f\"✓ January PWWB data shape: {X_jan_pwwb.shape}\")\n",
    "print(f\"  Channels: {channel_info['channel_order']}\")\n",
    "\n",
    "# ========== 2. Load January AirNow Data ==========\n",
    "print(\"\\nLoading January AirNow data...\")\n",
    "jan_airnow = AirNowData(\n",
    "    start_date=jan_start_date,\n",
    "    end_date=jan_end_date_adj,\n",
    "    extent=extent,\n",
    "    airnow_api_key=os.getenv('AIRNOW_API_KEY'),\n",
    "    frames_per_sample=frames_per_sample,\n",
    "    dim=dim,\n",
    "    elevation_path=\"../libs/inputs/elevation.npy\",\n",
    "    mask_path=\"../libs/inputs/mask.npy\",\n",
    "    force_reprocess=False\n",
    ")\n",
    "X_jan_airnow = jan_airnow.data\n",
    "Y_jan = jan_airnow.target_stations\n",
    "print(f\"✓ January AirNow data shape: {X_jan_airnow.shape}\")\n",
    "if Y_jan is not None:\n",
    "    print(f\"  January target stations shape: {Y_jan.shape}\")\n",
    "else:\n",
    "    print(\"  No January target stations available\")\n",
    "\n",
    "# ========== 3. Load January HRRR Data ==========\n",
    "print(\"\\nLoading January HRRR data...\")\n",
    "jan_hrrr = HRRRData(\n",
    "    start_date=jan_start_date,\n",
    "    end_date=jan_end_date_adj,\n",
    "    extent=extent,\n",
    "    extent_name='la_region',\n",
    "    product='COLMD',\n",
    "    frames_per_sample=frames_per_sample,\n",
    "    dim=dim,\n",
    "    verbose=True,\n",
    "    sample_setting=2\n",
    ")\n",
    "X_jan_hrrr = jan_hrrr.data\n",
    "print(f\"✓ January HRRR data shape: {X_jan_hrrr.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create_experiments",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== 4. Create Experiment 4 dataset ==========\n",
    "print(\"\\nCreating Experiment 4 dataset...\")\n",
    "\n",
    "# Experiment 4: Fire January set + HRRR\n",
    "print(\"  Experiment 4: Fire January set + HRRR\")\n",
    "X_exp4 = np.concatenate([X_jan_pwwb, X_jan_airnow, X_jan_hrrr], axis=-1)\n",
    "print(f\"    Combined shape: {X_exp4.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data_splits",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== 5. Train/Test Split for experiment ==========\n",
    "print(\"\\nCreating train/test splits for experiment...\")\n",
    "# Experiment 4 splits\n",
    "X_exp4_train, X_exp4_test = train_test_split(X_exp4, train_size=0.75)\n",
    "Y_jan_train, Y_jan_test = train_test_split(Y_jan, train_size=0.75)\n",
    "print(f\"  Experiment 4: Train={X_exp4_train.shape}, Test={X_exp4_test.shape}\")\n",
    "\n",
    "# ========== 6. Standardize data ==========\n",
    "print(\"\\nStandardizing data...\")\n",
    "\n",
    "# Experiment 4 standardization\n",
    "X_exp4_train_scaled, X_exp4_test_scaled = std_scale(X_exp4_train, X_exp4_test)\n",
    "print(f\"  Experiment 4: Scaled train={X_exp4_train_scaled.shape}, test={X_exp4_test_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save_datasets",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== 7. Save prepared datasets ==========\n",
    "print(\"\\nSaving prepared dataset...\")\n",
    "\n",
    "# Create directory for experiment\n",
    "exp_dir = os.path.join(output_dir, \"experiment4\")\n",
    "os.makedirs(exp_dir, exist_ok=True)\n",
    "\n",
    "# Save Experiment 4 data\n",
    "np.save(os.path.join(exp_dir, \"X_train.npy\"), X_exp4_train_scaled)\n",
    "np.save(os.path.join(exp_dir, \"X_test.npy\"), X_exp4_test_scaled)\n",
    "np.save(os.path.join(exp_dir, \"y_train.npy\"), Y_jan_train)\n",
    "np.save(os.path.join(exp_dir, \"y_test.npy\"), Y_jan_test)\n",
    "\n",
    "print(\"\\n✓ Dataset prepared and saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6812d262-11a1-4927-926e-9ad0682975f9",
   "metadata": {},
   "source": [
    "# Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf1eba7-2cbd-485a-a9da-1c46ba2d01d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to visualize data from experiment\n",
    "def visualize_experiment_data(X, y, sample_idx=None):\n",
    "    \"\"\"Visualize data from the experiment\"\"\"\n",
    "    # Get a random sample if none provided\n",
    "    if sample_idx is None:\n",
    "        np.random.seed(42)\n",
    "        sample_idx = np.random.choice(range(len(X)), size=1)[0]\n",
    "    \n",
    "    # Get channel information\n",
    "    n_channels = X.shape[4]\n",
    "    n_frames = X.shape[1]\n",
    "    \n",
    "    # Create figure\n",
    "    fig, axes = plt.subplots(n_channels, n_frames, figsize=(3*n_frames, 2*n_channels))\n",
    "    if n_channels == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    # Plot each channel and frame\n",
    "    for c in range(n_channels):\n",
    "        for f in range(n_frames):\n",
    "            ax = axes[c, f]\n",
    "            ax.imshow(X[sample_idx, f, :, :, c])\n",
    "            if f == 0:\n",
    "                ax.set_ylabel(f\"Channel {c}\")\n",
    "            ax.set_title(f\"Frame {f+1}\")\n",
    "            ax.axis(\"off\")\n",
    "    \n",
    "    # Set title\n",
    "    plt.suptitle(f\"Experiment 4: Fire January set + HRRR\\nSample {sample_idx}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print target values\n",
    "    print(f\"Target values: {y[sample_idx]}\")\n",
    "\n",
    "# Visualize a sample from the experiment\n",
    "print(\"Visualizing data...\")\n",
    "visualize_experiment_data(X_exp4_train_scaled, Y_jan_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df24d06-dd0d-43e5-9882-433592c04ac3",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c4bb57-54cf-4ee5-8805-a25b32b79da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv3D\n",
    "from keras.layers import ConvLSTM2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Convolution2D, MaxPooling3D, Flatten, Reshape\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense\n",
    "from keras.layers import InputLayer\n",
    "\n",
    "tf.keras.backend.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b8f7aa-b358-4828-9d23-dcfe919ed971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Experiment 4: Fire January set + HRRR\n",
    "print(\"\\n==== Running Experiment 4: Fire January set + HRRR ====\")\n",
    "print(f\"Training data shape: {X_exp4_train_scaled.shape}\")\n",
    "print(f\"Target data shape: {Y_jan_train.shape}\")\n",
    "\n",
    "# Build model\n",
    "seq = Sequential()\n",
    "\n",
    "seq.add(\n",
    "    InputLayer(shape=X_exp4_train_scaled.shape[1:])\n",
    ")\n",
    "\n",
    "seq.add(\n",
    "    ConvLSTM2D(\n",
    "            filters=15, \n",
    "            kernel_size=(3, 3),\n",
    "            padding='same', \n",
    "            return_sequences=True\n",
    "    )\n",
    ")\n",
    "\n",
    "seq.add(\n",
    "    ConvLSTM2D(\n",
    "        filters=30, \n",
    "        kernel_size=(3, 3),\n",
    "        padding='same', \n",
    "        return_sequences=True\n",
    "    )\n",
    ")\n",
    "\n",
    "seq.add(\n",
    "    Conv3D(\n",
    "        filters=15, \n",
    "        kernel_size=(3, 3, 3),\n",
    "        activation='relu',\n",
    "        padding='same'    \n",
    "    )\n",
    ")\n",
    "\n",
    "seq.add(\n",
    "    Conv3D(\n",
    "        filters=1, \n",
    "        kernel_size=(3, 3, 3),\n",
    "        activation='relu',\n",
    "        padding='same'\n",
    "    )\n",
    ")\n",
    "\n",
    "seq.add(Flatten())\n",
    "seq.add(Dense(Y_jan_train.shape[1], activation='relu'))\n",
    "\n",
    "# Compile model\n",
    "seq.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "\n",
    "# Print model summary\n",
    "seq.summary()\n",
    "\n",
    "# Train model\n",
    "print(f\"\\nTraining model...\")\n",
    "epochs = 50  # Reduced epochs for faster testing\n",
    "batch_size = 4\n",
    "history = seq.fit(\n",
    "    X_exp4_train_scaled, Y_jan_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "# Evaluate model\n",
    "print(f\"\\nEvaluating model...\")\n",
    "test_loss = seq.evaluate(X_exp4_test_scaled, Y_jan_test, verbose=0)\n",
    "print(f\"Test MAE: {test_loss:.4f}\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred = seq.predict(X_exp4_test_scaled, verbose=0)\n",
    "\n",
    "# Calculate metrics\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "mae = mean_absolute_error(Y_jan_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(Y_jan_test, y_pred))\n",
    "r2 = r2_score(Y_jan_test, y_pred)\n",
    "\n",
    "print(f\"Mean Absolute Error: {mae:.4f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse:.4f}\")\n",
    "print(f\"R² Score: {r2:.4f}\")\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "if 'val_loss' in history.history:\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.legend()\n",
    "plt.title('Experiment 4: Fire January set + HRRR\\nTraining Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss (MAE)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Save results\n",
    "results_dir = os.path.join(output_dir, \"experiment4\", \"results\")\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "np.save(os.path.join(results_dir, \"y_pred.npy\"), y_pred)\n",
    "seq.save(os.path.join(results_dir, \"model.h5\"))\n",
    "\n",
    "exp4_results = {\n",
    "    'model': seq,\n",
    "    'history': history,\n",
    "    'loss': test_loss,\n",
    "    'mae': mae,\n",
    "    'rmse': rmse,\n",
    "    'r2': r2,\n",
    "    'y_pred': y_pred,\n",
    "    'y_test': Y_jan_test\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a464ca9a-7130-4c6e-a342-5e8c5a9baa11",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa443727-40fc-46e0-9310-e39639290d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze results\n",
    "print(f\"\\nDetailed analysis for Experiment 4:\")\n",
    "X_test = X_exp4_test_scaled\n",
    "y_test = Y_jan_test\n",
    "y_pred = exp4_results['y_pred']\n",
    "model = exp4_results['model']\n",
    "description = \"Fire January set + HRRR, 2nd week\"\n",
    "\n",
    "print(f\"Analyzing Experiment 4: {description}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953b3905-4697-441f-a66f-635d8c90221d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs.plotting import (\n",
    "    plot_prediction_comparison,\n",
    "    plot_scatter_comparison,\n",
    "    plot_error_by_sensor,\n",
    "    plot_time_series_comparison,\n",
    "    plot_input_frames,\n",
    "    print_metrics\n",
    ")\n",
    "\n",
    "# Sensor names (use AirNow sensor names if available)\n",
    "if hasattr(jan_airnow, 'sensor_names') and jan_airnow.sensor_names is not None:\n",
    "    sensor_names = jan_airnow.sensor_names\n",
    "else:\n",
    "    sensor_names = [\"North Hollywood\", \"Los Angeles - N. Main Street\", \"Compton\"]\n",
    "\n",
    "print(\"\\n1. Plotting prediction comparison...\")\n",
    "plot_prediction_comparison(y_pred, y_test, sensor_names, sample_idx=12)\n",
    "\n",
    "print(\"\\n2. Plotting scatter comparison...\")\n",
    "plot_scatter_comparison(y_pred, y_test)\n",
    "\n",
    "print(\"\\n3. Plotting error by sensor...\")\n",
    "plot_error_by_sensor(y_pred, y_test, sensor_names)\n",
    "\n",
    "print(\"\\n4. Plotting time series comparison...\")\n",
    "plot_time_series_comparison(y_pred, y_test, sensor_names)\n",
    "    \n",
    "print(\"\\n5. Plotting time series with shifted predictions...\")\n",
    "plot_time_series_comparison(y_pred, y_test, sensor_names, shift_pred=1)\n",
    "\n",
    "print(\"\\n6. Printing metrics...\")\n",
    "print_metrics(y_pred, y_test, sensor_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save_exp_results",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save experiment comparison\n",
    "with open(os.path.join(output_dir, 'experiment4_results.txt'), 'w') as f:\n",
    "    f.write(\"==== Experiment 4 Results ====\\n\")\n",
    "    f.write(f\"Experiment 4 (Fire January set + HRRR, 2nd week): MAE = {exp4_results['mae']:.4f}, RMSE = {exp4_results['rmse']:.4f}, R² = {exp4_results['r2']:.4f}\\n\")\n",
    "    f.write(f\"\\nAnalysis completed on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "print(\"\\nExperiment 4 complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hysplitrevised",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
