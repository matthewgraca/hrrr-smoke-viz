{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "deca3910-8b85-4d35-ba11-4278b6cfa502",
   "metadata": {},
   "source": [
    "# Usage\n",
    "Ideally the only thing that needs to be changed is: \n",
    "- The start/end date of the data\n",
    "- The data ingestion portion\n",
    "\n",
    "The rest should be taken care of, assuming no bugs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c92945-842a-4338-9ec2-a954bca054a8",
   "metadata": {},
   "source": [
    "# Data parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a247a5-a0e5-46f7-adbd-3234c2f952d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define bounding box\n",
    "lat_bottom, lat_top = 33.9, 34.2\n",
    "lon_bottom, lon_top = -118.4, -118.0\n",
    "extent = (lon_bottom, lon_top, lat_bottom, lat_top)\n",
    "\n",
    "# input data shape\n",
    "dim = 200\n",
    "frames_per_sample = 5\n",
    "\n",
    "# date range of data\n",
    "start_date, end_date = \"2024-12-01-00\", \"2024-12-31-23\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a17cf45-39ee-4320-a2b6-93bf9c095667",
   "metadata": {},
   "source": [
    "# Data ingestion and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cd894d-b165-4b11-9d41-0608bdf6783e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python nonsense that allows you to import from sibling directories\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import numpy as np\n",
    "# split data\n",
    "def train_test_split(X, train_size=0.75):\n",
    "    split_idx = int(X.shape[0] * train_size)\n",
    "    X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "    \n",
    "    return X_train, X_test\n",
    "\n",
    "# scale training data, then scale test data based on training data stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "def std_scale(X_train, X_test):\n",
    "    scaler = StandardScaler()\n",
    "    scaled_train = scaler.fit_transform(X_train.reshape(-1, 1)).reshape(X_train.shape)\n",
    "    scaled_test = scaler.transform(X_test.reshape(-1, 1)).reshape(X_test.shape)\n",
    "\n",
    "    return scaled_train, scaled_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caf992c-de0b-474a-aa02-d3c50d7649fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ingest data here; maiac, airnow, hrrr, etc.\n",
    "X_1 = ... # replace X_1 with dataset; e.g. X_hrrr = HD.data\n",
    "\n",
    "# train-test split\n",
    "X_1_train, X_1_test = train_test_split(X_1, train_size=0.75)\n",
    "X_airnow_train, X_airnow_test = train_test_split(X_airnow, train_size=0.75)\n",
    "y_train, y_test = train_test_split(Y, train_size=0.75)\n",
    "\n",
    "# scale dataset\n",
    "X_1_train, X_1_test = std_scale(X_1_train, X_1_test)\n",
    "...\n",
    "\n",
    "# merge datasets into a 5D tensor\n",
    "X_train = np.concatenate([...], axis=-1)\n",
    "X_test = np.concatenate([...], axis=-1)\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6812d262-11a1-4927-926e-9ad0682975f9",
   "metadata": {},
   "source": [
    "# Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf1eba7-2cbd-485a-a9da-1c46ba2d01d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Construct a figure on which we will visualize the images.\n",
    "n_channels = X_train.shape[4]\n",
    "fig, axes = plt.subplots(n_channels, 5, figsize=(10, 12))\n",
    "\n",
    "# plot channels of a random data sample\n",
    "np.random.seed(42)\n",
    "rand_sample = np.random.choice(range(len(X_train)), size=1)[0]\n",
    "for c in range(n_channels):\n",
    "    for idx, ax in enumerate(axes[c]):\n",
    "        ax.imshow(np.squeeze(X_train[rand_sample, idx, :, :, c]))\n",
    "        ax.set_title(f\"Frame {idx + 1}\")\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "# Print information and display the figure.\n",
    "print(f\"Displaying frames for example {rand_sample}.\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Target: \", y_train[rand_sample])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df24d06-dd0d-43e5-9882-433592c04ac3",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c4bb57-54cf-4ee5-8805-a25b32b79da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv3D\n",
    "from keras.layers import ConvLSTM2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Convolution2D, MaxPooling3D, Flatten, Reshape\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense\n",
    "from keras.layers import InputLayer\n",
    "\n",
    "tf.keras.backend.set_image_data_format('channels_last')\n",
    "\n",
    "seq = Sequential()\n",
    "\n",
    "seq.add(\n",
    "    InputLayer(shape=(5, 200, 200, 6))\n",
    ")\n",
    "\n",
    "seq.add(\n",
    "    ConvLSTM2D(\n",
    "            filters=15, \n",
    "            kernel_size=(3, 3),\n",
    "            padding='same', \n",
    "            return_sequences=True\n",
    "    )\n",
    ")\n",
    "\n",
    "seq.add(\n",
    "    ConvLSTM2D(\n",
    "        filters=30, \n",
    "        kernel_size=(3, 3),\n",
    "        padding='same', \n",
    "        return_sequences=True\n",
    "    )\n",
    ")\n",
    "\n",
    "seq.add(\n",
    "    Conv3D(\n",
    "        filters=15, \n",
    "        kernel_size=(3, 3, 3),\n",
    "        activation='relu',\n",
    "        padding='same'    \n",
    "    )\n",
    ")\n",
    "\n",
    "seq.add(\n",
    "    Conv3D(\n",
    "        filters=1, \n",
    "        kernel_size=(3, 3, 3),\n",
    "        activation='relu',\n",
    "        padding='same'\n",
    "    )\n",
    ")\n",
    "\n",
    "seq.add(Flatten())\n",
    "\n",
    "seq.add(Dense(3,activation='relu'))\n",
    "\n",
    "seq.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "seq.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b8f7aa-b358-4828-9d23-dcfe919ed971",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq.fit(X_train, y_train, batch_size=4, epochs=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a464ca9a-7130-4c6e-a342-5e8c5a9baa11",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132fd31c-07e5-4e96-8c19-6996ca5aeb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import mean_squared_error as mse\n",
    "\n",
    "# hardcode sensor locations for now because using precomputed, saved .npy files for airnow\n",
    "# otherwise, you can dynamically access the sensor locations with\n",
    "# list(AD.air_sens_loc.keys())\n",
    "air_sensor_loc = [\"North Holywood\", \"Los Angeles - N. Main Street\", \"Compton\"]\n",
    "\n",
    "def rmse(y_pred, y_test):\n",
    "    return np.sqrt(mse(y_pred, y_test))\n",
    "\n",
    "def nrmse(y_pred, y_test):\n",
    "    return rmse(y_pred, y_test) / np.mean(y_test) * 100\n",
    "    \n",
    "print(\"Input: Interpolated Previous PM2.5 Sensor data + HRRR-smoke data\")\n",
    "print(\"Output: Future PM 2.5 Sensor data at 6 Locations in LA County Hourly (Using 5 previous frames to predict 5 future frames) \\n\")\n",
    "\n",
    "print(\"RESULTS\")\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "print(f\"All Days All Locations - y_pred vs y_test Raw RMSE: {rmse(y_pred, y_test):.2f}\")\n",
    "print(f\"All Days All Locations - y_pred vs y_test RMSE Percent Error of Mean: {nrmse(y_pred, y_test):.2f}%\\n\")\n",
    "\n",
    "print(\"RESULTS BY FRAME\")\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "for i in range(5):\n",
    "    print(f\"Frame {i+1} (Hour {i+1}) All Locations - Raw RMSE: {rmse(y_pred[i,:], y_test[i,:]):.2f}\")\n",
    "    print(f\"Frame {i+1} (Hour {i+1}) All Locations - RMSE Percent Error of Mean: {nrmse(y_pred[i,:], y_test[i,:]):.2f}%\\n\")\n",
    "\n",
    "print(\"RESULTS BY SENSOR LOCATION\")\n",
    "print(\"---------------------------------------------------------------------------\")\n",
    "#for i, loc in enumerate(list(AD.air_sens_loc.keys())):\n",
    "for i, loc in enumerate(air_sensor_loc):\n",
    "    print(f\"All Days - {loc} Raw RMSE: {rmse(y_pred[:,i], y_test[:,i]):.2f}\")\n",
    "    print(f\"All Days - {loc} RMSE Percent Error of Mean: {nrmse(y_pred[:,i], y_test[:,i]):.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97db803-8f07-44bc-8f74-1dcff5dd07a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nVisualizing model predictions vs actual values...\")\n",
    "\n",
    "# Choose the first test sample for consistent visualizations\n",
    "sample_idx = 0\n",
    "\n",
    "# Create a bar chart comparing predicted vs actual values for each sensor\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "#sensor_names = list(AD.air_sens_loc.keys())\n",
    "sensor_names = air_sensor_loc\n",
    "x = np.arange(len(sensor_names))\n",
    "width = 0.35\n",
    "\n",
    "true_vals = y_test[sample_idx]\n",
    "pred_vals = y_pred[sample_idx]\n",
    "\n",
    "rects1 = ax.bar(x - width/2, true_vals, width, label='Actual')\n",
    "rects2 = ax.bar(x + width/2, pred_vals, width, label='Predicted')\n",
    "\n",
    "ax.set_title('PM2.5 Actual vs. Predicted Values by Sensor Location')\n",
    "ax.set_ylabel('PM2.5 Value')\n",
    "ax.set_xlabel('Sensor Location')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(sensor_names, rotation=45, ha='right')\n",
    "ax.legend()\n",
    "\n",
    "#plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create a scatter plot of predicted vs actual values\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(y_test.flatten(), y_pred.flatten(), alpha=0.5)\n",
    "plt.plot([0, np.max(y_test)], [0, np.max(y_test)], 'r--')  # Perfect prediction line\n",
    "plt.xlabel('Actual PM2.5 Values')\n",
    "plt.ylabel('Predicted PM2.5 Values')\n",
    "plt.title('Actual vs. Predicted PM2.5 Values')\n",
    "plt.grid(True)\n",
    "#plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compute error metrics for each sensor\n",
    "error_by_sensor = []\n",
    "for i, sensor in enumerate(sensor_names):\n",
    "    error = rmse(y_pred[:, i], y_test[:, i])\n",
    "    error_by_sensor.append(error)\n",
    "\n",
    "# Create bar chart of errors by sensor\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(sensor_names, error_by_sensor)\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('Prediction Error by Sensor Location')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "#plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e614ae-7f83-4d21-bb46-d8b14fa38e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "for i, sensor in enumerate(air_sensor_loc):\n",
    "    plt.subplot(3, 2, i + 1)\n",
    "    plt.plot(y_test[:, i], label='Actual', marker='o')\n",
    "    plt.plot(y_pred[:, i], label='Predicted', marker='x')\n",
    "    plt.title(f'Sensor: {sensor}')\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('PM2.5')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
