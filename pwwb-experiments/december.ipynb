{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "deca3910-8b85-4d35-ba11-4278b6cfa502",
   "metadata": {},
   "source": [
    "# Experiment 1: No-fire December set (PWWB + AirNow)\n",
    "\n",
    "This notebook focuses on running Experiment 1, which uses data from December (no-fire period) combining PWWB and AirNow datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c92945-842a-4338-9ec2-a954bca054a8",
   "metadata": {},
   "source": [
    "# Data parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95a247a5-a0e5-46f7-adbd-3234c2f952d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define bounding box\n",
    "lat_bottom, lat_top = 33.5, 34.5\n",
    "lon_bottom, lon_top = -118.75, -117.0\n",
    "extent = (lon_bottom, lon_top, lat_bottom, lat_top)\n",
    "\n",
    "# input data shape\n",
    "dim = 200\n",
    "frames_per_sample = 5\n",
    "\n",
    "# date range of data - two weeks of December for this experiment 2024-12-08-00\", \"2024-12-21-00\"\n",
    "dec_start_date, dec_end_date = \"2024-12-01-00\", \"2025-01-01-00\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a17cf45-39ee-4320-a2b6-93bf9c095667",
   "metadata": {},
   "source": [
    "# Data ingestion and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28cd894d-b165-4b11-9d41-0608bdf6783e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moh/miniconda3/envs/hysplitrevised/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# python nonsense that allows you to import from sibling directories\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Import the new PWWB implementation and dataset manager\n",
    "from libs.pwwb import PWWBData\n",
    "from libs.pwwb.utils.dataset_manager import create_dataset_manager\n",
    "\n",
    "# Import the AirNow data class\n",
    "from libs.airnowdata import AirNowData\n",
    "\n",
    "# Load environment variables (API keys, credentials)\n",
    "load_dotenv()\n",
    "\n",
    "# split data\n",
    "def train_test_split(X, train_size=0.75):\n",
    "    split_idx = int(X.shape[0] * train_size)\n",
    "    X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "    \n",
    "    return X_train, X_test\n",
    "\n",
    "# scale training data, then scale test data based on training data stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "def std_scale(X_train, X_test):\n",
    "    scaler = StandardScaler()\n",
    "    scaled_train = scaler.fit_transform(X_train.reshape(-1, 1)).reshape(X_train.shape)\n",
    "    scaled_test = scaler.transform(X_test.reshape(-1, 1)).reshape(X_test.shape)\n",
    "\n",
    "    return scaled_train, scaled_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "setup_dataset_manager",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing datasets:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>created</th>\n",
       "      <th>description</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>channels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dec2024_MAIC_TROPOMI_N02_METAR_WIND</td>\n",
       "      <td>2025-05-20T17:58:39.575630</td>\n",
       "      <td>December 2024 - month with MAIAC, TROPOMI NO2,...</td>\n",
       "      <td>2024-12-01-00</td>\n",
       "      <td>2024-12-3-00</td>\n",
       "      <td>maiac, tropomi, metar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dec2024_MAIC_TROPOMI_N02_METAR_WIND_UV_ONLY</td>\n",
       "      <td>2025-05-20T18:34:46.342993</td>\n",
       "      <td>December 2024 - month with MAIAC, TROPOMI NO2,...</td>\n",
       "      <td>2024-12-01-00</td>\n",
       "      <td>2024-12-3-00</td>\n",
       "      <td>maiac, tropomi, metar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          name                     created  \\\n",
       "0          dec2024_MAIC_TROPOMI_N02_METAR_WIND  2025-05-20T17:58:39.575630   \n",
       "1  dec2024_MAIC_TROPOMI_N02_METAR_WIND_UV_ONLY  2025-05-20T18:34:46.342993   \n",
       "\n",
       "                                         description     start_date  \\\n",
       "0  December 2024 - month with MAIAC, TROPOMI NO2,...  2024-12-01-00   \n",
       "1  December 2024 - month with MAIAC, TROPOMI NO2,...  2024-12-01-00   \n",
       "\n",
       "       end_date               channels  \n",
       "0  2024-12-3-00  maiac, tropomi, metar  \n",
       "1  2024-12-3-00  maiac, tropomi, metar  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create output directory for results\n",
    "output_dir = \"experiment_output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Create dataset manager\n",
    "manager = create_dataset_manager(\n",
    "    registry_file=\"experiment1_registry.json\",\n",
    "    cache_dir=\"data/pwwb_cache/\"\n",
    ")\n",
    "\n",
    "# List existing datasets\n",
    "print(\"Existing datasets:\")\n",
    "try:\n",
    "    display(manager.list_datasets())\n",
    "except:\n",
    "    print(\"No existing datasets found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "process_dec_data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading December PWWB data...\n",
      "Dataset 'dec2024_MAIC_TROPOMI_N02_METAR_WIND_UV_ONLY' already exists, loading from cache...\n",
      "Using cache prefix: dec2024_MAIC_TROPOMI_N02_METAR_WIND_UV_ONLY_\n",
      "Initialized PWWBData with 48 hourly timestamps\n",
      "Date range: 2024-12-01 00:00:00 to 2024-12-02 23:00:00\n",
      "Channels included: ['maiac', 'tropomi', 'metar']\n",
      "TROPOMI channels: ['TROPOMI_NO2']\n",
      "METAR channels: ['METAR_Wind_U', 'METAR_Wind_V']\n",
      "Processing MAIAC AOD data...\n",
      "Fetching MAIAC AOD data for 2 unique dates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moh/wildfire/hrrr-smoke-viz/pwwb-experiments/../libs/pwwb/pwwb_data.py:115: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  self.timestamps = pd.date_range(self.start_date, self.end_date, freq='H')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AOD data shape before resize: (5, 1200, 1200)\n",
      "AOD data type: int16\n",
      "AOD data min/max: -28672/1180\n",
      "Averaged AOD data to shape: (1200, 1200)\n",
      "Resized AOD data to shape: (200, 200)\n",
      "Successfully processed AOD data for 2024-12-01\n",
      "AOD data shape before resize: (4, 1200, 1200)\n",
      "AOD data type: int16\n",
      "AOD data min/max: -28672/582\n",
      "Averaged AOD data to shape: (1200, 1200)\n",
      "Resized AOD data to shape: (200, 200)\n",
      "Successfully processed AOD data for 2024-12-02\n",
      "Created MAIAC AOD data with shape (48, 200, 200, 1)\n",
      "Processing TROPOMI data...\n",
      "Including TROPOMI channels: ['TROPOMI_NO2']\n",
      "Fetching TROPOMI data for 2 unique dates\n",
      "Processing TROPOMI products: ['NO2']\n",
      "Processing TROPOMI data for date: 2024-12-01\n",
      "Successfully processed NO2 data\n",
      "Processing TROPOMI data for date: 2024-12-02\n",
      "Successfully processed NO2 data\n",
      "Created TROPOMI data with shape (48, 200, 200, 1)\n",
      "Processing METAR meteorological data...\n",
      "Initialized MetarDataSource with 2 channels: ['METAR_Wind_U', 'METAR_Wind_V']\n",
      "Will fetch these raw variables: ['sped', 'drct']\n",
      "Will calculate wind U/V components from speed/direction\n",
      "Including METAR variables: ['sped', 'drct']\n",
      "Preparing data for channels: ['METAR_Wind_U', 'METAR_Wind_V']\n",
      "Using 4 METAR stations for meteorological data:\n",
      "  LAX - Los Angeles Intl (33.9382, -118.3865)\n",
      "  HHR - Hawthorne Municipal (33.9228, -118.3352)\n",
      "  EMT - El Monte (34.086, -118.035)\n",
      "  CQT - Los Angeles Downtown/USC (34.0235, -118.2912)\n",
      "Fetching METAR data chunk: 2024-12-01 to 2024-12-02\n",
      "Fetching METAR data from 2024-11-30 23:00:00 to 2024-12-03 00:00:00\n",
      "Requesting METAR data for 4 stations from 2024-11-30 23:00 to 2024-12-03 00:00\n",
      "Raw METAR data saved to data/pwwb_cache/dec2024_MAIC_TROPOMI_N02_METAR_WIND_UV_ONLY_metar_20241130_2300_to_20241203_0000_routine_only.csv\n",
      "Successfully parsed CSV data with 114 records\n",
      "  Processed 50 records for station LAX\n",
      "  Processed 50 records for station HHR\n",
      "  Processed 50 records for station EMT\n",
      "  No data available for station CQT\n",
      "METAR data fetching complete\n",
      "  Station LAX: 50 total records\n",
      "  Station HHR: 50 total records\n",
      "  Station EMT: 50 total records\n",
      "  Station CQT: 0 total records\n",
      "Computed wind U/V components from speed/direction\n",
      "U component range: -5.75 to 11.33\n",
      "V component range: -5.75 to 6.48\n",
      "Processing 48 timestamps of METAR data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moh/wildfire/hrrr-smoke-viz/pwwb-experiments/../libs/pwwb/data_sources/metar_data.py:574: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  full_date_range = pd.date_range(start=start_date_with_margin, end=end_date_with_margin, freq='H')\n",
      "/home/moh/wildfire/hrrr-smoke-viz/pwwb-experiments/../libs/pwwb/data_sources/metar_data.py:616: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  station_df['timestep'] = station_df['valid'].dt.ceil('H')\n",
      "/home/moh/wildfire/hrrr-smoke-viz/pwwb-experiments/../libs/pwwb/data_sources/metar_data.py:616: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  station_df['timestep'] = station_df['valid'].dt.ceil('H')\n",
      "/home/moh/wildfire/hrrr-smoke-viz/pwwb-experiments/../libs/pwwb/data_sources/metar_data.py:616: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  station_df['timestep'] = station_df['valid'].dt.ceil('H')\n",
      "/home/moh/wildfire/hrrr-smoke-viz/pwwb-experiments/../libs/pwwb/data_sources/metar_data.py:228: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  full_range = pd.date_range(start=self.timestamps[0], end=self.timestamps[-1], freq='H')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created METAR data with shape (48, 200, 200, 2)\n",
      "Final channels: ['METAR_Wind_U', 'METAR_Wind_V']\n",
      "METAR_Wind_U sample stats: min=5.75, max=6.48, mean=6.09\n",
      "METAR_Wind_V sample stats: min=0.00, max=2.36, mean=0.06\n",
      "Saving data to cache: data/pwwb_cache/dec2024_MAIC_TROPOMI_N02_METAR_WIND_UV_ONLY_metar_u_v_data.npy\n",
      "Final data shape: (44, 5, 200, 200, 4)\n",
      "\n",
      "Channel Statistics:\n",
      "===================\n",
      "\n",
      "Channel 0: MAIAC_AOD\n",
      "  Min: -28672.000000000007\n",
      "  Max: -11408.21815610717\n",
      "  Mean: -22674.333462043887\n",
      "  Std: 5129.642805682386\n",
      "  Data coverage: 100.00% (40000/40000 non-zero pixels)\n",
      "\n",
      "Channel 1: TROPOMI_NO2\n",
      "  Min: 0.00012060817200200961\n",
      "  Max: 0.0005489974885201102\n",
      "  Mean: 0.00029664643713431493\n",
      "  Std: 8.174618747433876e-05\n",
      "  Data coverage: 100.00% (40000/40000 non-zero pixels)\n",
      "\n",
      "Channel 2: METAR_Wind_U\n",
      "  Min: 5.75\n",
      "  Max: 6.483879083422768\n",
      "  Mean: 6.086833897749474\n",
      "  Std: 0.0759926512972382\n",
      "  Data coverage: 100.00% (40000/40000 non-zero pixels)\n",
      "\n",
      "Channel 3: METAR_Wind_V\n",
      "  Min: 0.0\n",
      "  Max: 2.359938988947114\n",
      "  Mean: 0.06280266341815492\n",
      "  Std: 0.27971648397314036\n",
      "  Data coverage: 6.71% (2685/40000 non-zero pixels)\n",
      "\n",
      "Final Data Shape:\n",
      "  44 samples\n",
      "  5 frames per sample\n",
      "  200x200 grid size\n",
      "  4 channels\n",
      "\n",
      "Data Memory Usage:\n",
      "  268.55 MB\n",
      "Data file data/pwwb_cache/dec2024_MAIC_TROPOMI_N02_METAR_WIND_UV_ONLY_full_data.npy does not exist. Cannot load data.\n",
      "Warning: Created PWWBData instance but could not load cached data.\n",
      "✓ December PWWB data shape: (44, 5, 200, 200, 4)\n",
      "  Channels: ['MAIAC_AOD', 'TROPOMI_NO2', 'METAR_Wind_U', 'METAR_Wind_V']\n",
      "\n",
      "Loading December AirNow data...\n",
      "Using mask from ../libs/inputs/mask.npy\n",
      "Requesting data from AirNow API...\n",
      "JSON data saved to 'data/airnow.json'\n",
      "Loading AirNow data from data/airnow.json...\n",
      "Grouped AirNow data into 744 time frames\n",
      "Processing AirNow data with IDW interpolation (this may take time)...\n",
      "Interpolating 744 frames...\n",
      "Saving processed AirNow data to cache: data/airnow_processed.npz\n",
      "✓ Successfully saved processed data to cache\n",
      "✓ December AirNow data shape: (740, 5, 200, 200, 1)\n",
      "  December target stations shape: (740, 15)\n"
     ]
    }
   ],
   "source": [
    "# Adjust end date for AirNow\n",
    "dec_end_date_adj = pd.to_datetime(dec_end_date) - pd.Timedelta(hours=1)\n",
    "\n",
    "# Dataset name and description\n",
    "dataset_name = \"dec2024_MAIC_TROPOMI_N02_METAR_WIND_UV_ONLY\"\n",
    "dataset_desc = \"December 2024 - two weeks with MAIAC, TROPOMI NO2, METAR Wind U/V components only\"\n",
    "\n",
    "# ========== 1. Load December PWWB Data ==========\n",
    "print(\"\\nLoading December PWWB data...\")\n",
    "\n",
    "# Check if dataset already exists in the registry\n",
    "if manager.get_dataset_info(dataset_name) is not None:\n",
    "    print(f\"Dataset '{dataset_name}' already exists, loading from cache...\")\n",
    "    dec_pwwb = manager.load_dataset(dataset_name, PWWBData)\n",
    "else:\n",
    "    print(f\"Dataset '{dataset_name}' not found, creating new one...\")\n",
    "    # Create the dataset with the specified channels\n",
    "    dec_pwwb = manager.create_dataset(\n",
    "        name=dataset_name,\n",
    "        description=dataset_desc,\n",
    "        PWWBData_class=PWWBData,\n",
    "        start_date=dec_start_date,\n",
    "        end_date=dec_end_date,\n",
    "        extent=extent,\n",
    "        frames_per_sample=frames_per_sample,\n",
    "        dim=dim,\n",
    "        include_channels={\n",
    "            'maiac': True,                     # Include MAIAC AOD\n",
    "            'tropomi': ['TROPOMI_NO2'],        # Only include NO2 from TROPOMI\n",
    "            'metar': ['METAR_Wind_U', 'METAR_Wind_V'],  # Only wind components from METAR\n",
    "            'modis_fire': False,               # Exclude MODIS fire data\n",
    "            'merra2': False                    # Exclude MERRA2 data\n",
    "        },\n",
    "        verbose=True,\n",
    "        output_dir=output_dir\n",
    "    )\n",
    "    # Save the dataset\n",
    "    dec_pwwb.save_data()\n",
    "\n",
    "# Get the data and channel info\n",
    "X_dec_pwwb = dec_pwwb.data\n",
    "channel_info = dec_pwwb.get_channel_info()\n",
    "print(f\"✓ December PWWB data shape: {X_dec_pwwb.shape}\")\n",
    "print(f\"  Channels: {channel_info['channel_names']}\")\n",
    "\n",
    "# ========== 2. Load December AirNow Data ==========\n",
    "print(\"\\nLoading December AirNow data...\")\n",
    "dec_airnow = AirNowData(\n",
    "    start_date=dec_start_date,\n",
    "    end_date=dec_end_date_adj,\n",
    "    extent=extent,\n",
    "    airnow_api_key=os.getenv('AIRNOW_API_KEY'),\n",
    "    frames_per_sample=frames_per_sample,\n",
    "    dim=dim,\n",
    "    elevation_path=\"../libs/inputs/elevation.npy\",\n",
    "    mask_path=\"../libs/inputs/mask.npy\",\n",
    "    force_reprocess=False\n",
    ")\n",
    "X_dec_airnow = dec_airnow.data\n",
    "Y_dec = dec_airnow.target_stations\n",
    "print(f\"✓ December AirNow data shape: {X_dec_airnow.shape}\")\n",
    "if Y_dec is not None:\n",
    "    print(f\"  December target stations shape: {Y_dec.shape}\")\n",
    "else:\n",
    "    print(\"  No December target stations available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "create_experiments",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating Experiment 1 dataset...\n",
      "  Experiment 1: No-fire December set (PWWB + AirNow)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 44 and the array at index 1 has size 740",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Experiment 1: No-fire December set (PWWB + AirNow)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Experiment 1: No-fire December set (PWWB + AirNow)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m X_exp1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([X_dec_pwwb, X_dec_airnow], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Combined shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_exp1\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Display the number of channels from each source\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 44 and the array at index 1 has size 740"
     ]
    }
   ],
   "source": [
    "# ========== 3. Create Experiment 1 dataset ==========\n",
    "print(\"\\nCreating Experiment 1 dataset...\")\n",
    "\n",
    "# Experiment 1: No-fire December set (PWWB + AirNow)\n",
    "print(\"  Experiment 1: No-fire December set (PWWB + AirNow)\")\n",
    "X_exp1 = np.concatenate([X_dec_pwwb, X_dec_airnow], axis=-1)\n",
    "print(f\"    Combined shape: {X_exp1.shape}\")\n",
    "\n",
    "# Display the number of channels from each source\n",
    "pwwb_channels = X_dec_pwwb.shape[4]\n",
    "airnow_channels = X_dec_airnow.shape[4]\n",
    "print(f\"    PWWB channels: {pwwb_channels}, AirNow channels: {airnow_channels}, Total: {X_exp1.shape[4]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data_splits",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== 4. Train/Test Split for experiment ==========\n",
    "print(\"\\nCreating train/test splits for experiment...\")\n",
    "# Experiment 1 splits\n",
    "X_exp1_train, X_exp1_test = train_test_split(X_exp1, train_size=0.75)\n",
    "Y_dec_train, Y_dec_test = train_test_split(Y_dec, train_size=0.75)\n",
    "print(f\"  Experiment 1: Train={X_exp1_train.shape}, Test={X_exp1_test.shape}\")\n",
    "\n",
    "# ========== 5. Standardize data ==========\n",
    "print(\"\\nStandardizing data...\")\n",
    "\n",
    "# Experiment 1 standardization\n",
    "X_exp1_train_scaled, X_exp1_test_scaled = std_scale(X_exp1_train, X_exp1_test)\n",
    "print(f\"  Experiment 1: Scaled train={X_exp1_train_scaled.shape}, test={X_exp1_test_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save_datasets",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== 6. Save prepared datasets ==========\n",
    "print(\"\\nSaving prepared dataset...\")\n",
    "\n",
    "# Create directory for experiment\n",
    "exp_dir = os.path.join(output_dir, \"experiment1\")\n",
    "os.makedirs(exp_dir, exist_ok=True)\n",
    "\n",
    "# Save Experiment 1 data\n",
    "np.save(os.path.join(exp_dir, \"X_train.npy\"), X_exp1_train_scaled)\n",
    "np.save(os.path.join(exp_dir, \"X_test.npy\"), X_exp1_test_scaled)\n",
    "np.save(os.path.join(exp_dir, \"y_train.npy\"), Y_dec_train)\n",
    "np.save(os.path.join(exp_dir, \"y_test.npy\"), Y_dec_test)\n",
    "\n",
    "# Save metadata\n",
    "metadata = {\n",
    "    \"date_range\": f\"{dec_start_date} to {dec_end_date}\",\n",
    "    \"extent\": extent,\n",
    "    \"dim\": dim,\n",
    "    \"frames_per_sample\": frames_per_sample,\n",
    "    \"pwwb_channels\": channel_info['channel_names'],\n",
    "    \"airnow_channels\": [\"AirNow_PM25\"]\n",
    "}\n",
    "\n",
    "with open(os.path.join(exp_dir, \"metadata.json\"), \"w\") as f:\n",
    "    import json\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(\"\\n✓ Dataset prepared and saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6812d262-11a1-4927-926e-9ad0682975f9",
   "metadata": {},
   "source": [
    "# Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf1eba7-2cbd-485a-a9da-1c46ba2d01d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to visualize data from experiment\n",
    "def visualize_experiment_data(X, y, channel_names=None, sample_idx=None):\n",
    "    \"\"\"Visualize data from the experiment\"\"\"\n",
    "    # Get a random sample if none provided\n",
    "    if sample_idx is None:\n",
    "        np.random.seed(42)\n",
    "        sample_idx = np.random.choice(range(len(X)), size=1)[0]\n",
    "    \n",
    "    # Get channel information\n",
    "    n_channels = X.shape[4]\n",
    "    n_frames = X.shape[1]\n",
    "    \n",
    "    # Use provided channel names or create default ones\n",
    "    if channel_names is None or len(channel_names) != n_channels:\n",
    "        channel_names = [f\"Channel {i}\" for i in range(n_channels)]\n",
    "    \n",
    "    # Create figure\n",
    "    fig, axes = plt.subplots(n_channels, n_frames, figsize=(3*n_frames, 2*n_channels))\n",
    "    if n_channels == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    # Plot each channel and frame\n",
    "    for c in range(n_channels):\n",
    "        for f in range(n_frames):\n",
    "            ax = axes[c, f]\n",
    "            im = ax.imshow(X[sample_idx, f, :, :, c])\n",
    "            plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "            if f == 0:\n",
    "                ax.set_ylabel(channel_names[c])\n",
    "            ax.set_title(f\"Frame {f+1}\")\n",
    "    \n",
    "    # Set title\n",
    "    plt.suptitle(f\"Experiment 1: No-fire December set (PWWB + AirNow)\\nSample {sample_idx}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print target values\n",
    "    if y is not None:\n",
    "        print(f\"Target values: {y[sample_idx]}\")\n",
    "\n",
    "# Create combined channel names list\n",
    "all_channel_names = channel_info['channel_names'] + [\"AirNow_PM25\"]\n",
    "\n",
    "# Visualize a sample from the experiment\n",
    "print(\"Visualizing data...\")\n",
    "visualize_experiment_data(X_exp1_train_scaled, Y_dec_train, channel_names=all_channel_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df24d06-dd0d-43e5-9882-433592c04ac3",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c4bb57-54cf-4ee5-8805-a25b32b79da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv3D\n",
    "from keras.layers import ConvLSTM2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Convolution2D, MaxPooling3D, Flatten, Reshape\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense\n",
    "from keras.layers import InputLayer\n",
    "\n",
    "tf.keras.backend.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b8f7aa-b358-4828-9d23-dcfe919ed971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Experiment 1: No-fire December set (PWWB + AirNow)\n",
    "print(\"\\n==== Running Experiment 1: No-fire December set (PWWB + AirNow) ====\")\n",
    "print(f\"Training data shape: {X_exp1_train_scaled.shape}\")\n",
    "print(f\"Target data shape: {Y_dec_train.shape}\")\n",
    "\n",
    "# Build model\n",
    "seq = Sequential()\n",
    "\n",
    "seq.add(\n",
    "    InputLayer(shape=X_exp1_train_scaled.shape[1:])\n",
    ")\n",
    "\n",
    "seq.add(\n",
    "    ConvLSTM2D(\n",
    "            filters=15, \n",
    "            kernel_size=(3, 3),\n",
    "            padding='same', \n",
    "            return_sequences=True\n",
    "    )\n",
    ")\n",
    "\n",
    "seq.add(\n",
    "    ConvLSTM2D(\n",
    "        filters=30, \n",
    "        kernel_size=(3, 3),\n",
    "        padding='same', \n",
    "        return_sequences=True\n",
    "    )\n",
    ")\n",
    "\n",
    "seq.add(\n",
    "    Conv3D(\n",
    "        filters=15, \n",
    "        kernel_size=(3, 3, 3),\n",
    "        activation='relu',\n",
    "        padding='same'    \n",
    "    )\n",
    ")\n",
    "\n",
    "seq.add(\n",
    "    Conv3D(\n",
    "        filters=1, \n",
    "        kernel_size=(3, 3, 3),\n",
    "        activation='relu',\n",
    "        padding='same'\n",
    "    )\n",
    ")\n",
    "\n",
    "seq.add(Flatten())\n",
    "seq.add(Dense(Y_dec_train.shape[1], activation='relu'))\n",
    "\n",
    "# Compile model\n",
    "seq.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "\n",
    "# Print model summary\n",
    "seq.summary()\n",
    "\n",
    "# Train model\n",
    "print(f\"\\nTraining model...\")\n",
    "epochs = 100  # Reduced epochs for faster testing\n",
    "batch_size = 4\n",
    "history = seq.fit(\n",
    "    X_exp1_train_scaled, Y_dec_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "# Evaluate model\n",
    "print(f\"\\nEvaluating model...\")\n",
    "test_loss = seq.evaluate(X_exp1_test_scaled, Y_dec_test, verbose=0)\n",
    "print(f\"Test MAE: {test_loss:.4f}\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred = seq.predict(X_exp1_test_scaled, verbose=0)\n",
    "\n",
    "# Calculate metrics\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "mae = mean_absolute_error(Y_dec_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(Y_dec_test, y_pred))\n",
    "r2 = r2_score(Y_dec_test, y_pred)\n",
    "\n",
    "print(f\"Mean Absolute Error: {mae:.4f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse:.4f}\")\n",
    "print(f\"R² Score: {r2:.4f}\")\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "if 'val_loss' in history.history:\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.legend()\n",
    "plt.title('Experiment 1: No-fire December set (PWWB + AirNow)\\nTraining Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss (MAE)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Save results\n",
    "results_dir = os.path.join(output_dir, \"experiment1\", \"results\")\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "np.save(os.path.join(results_dir, \"y_pred.npy\"), y_pred)\n",
    "seq.save(os.path.join(results_dir, \"model.h5\"))\n",
    "\n",
    "exp1_results = {\n",
    "    'model': seq,\n",
    "    'history': history,\n",
    "    'loss': test_loss,\n",
    "    'mae': mae,\n",
    "    'rmse': rmse,\n",
    "    'r2': r2,\n",
    "    'y_pred': y_pred,\n",
    "    'y_test': Y_dec_test\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a464ca9a-7130-4c6e-a342-5e8c5a9baa11",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa443727-40fc-46e0-9310-e39639290d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nDetailed analysis for Experiment 1:\")\n",
    "X_test = X_exp1_test_scaled\n",
    "y_test = Y_dec_test\n",
    "y_pred = exp1_results['y_pred']\n",
    "model = exp1_results['model']\n",
    "description = \"No-fire December set (PWWB + AirNow), two weeks\"\n",
    "\n",
    "print(f\"Analyzing Experiment 1: {description}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953b3905-4697-441f-a66f-635d8c90221d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs.plotting import (\n",
    "    plot_prediction_comparison,\n",
    "    plot_scatter_comparison,\n",
    "    plot_error_by_sensor,\n",
    "    plot_time_series_comparison,\n",
    "    plot_input_frames,\n",
    "    print_metrics\n",
    ")\n",
    "\n",
    "# Sensor names (use AirNow sensor names if available)\n",
    "if hasattr(dec_airnow, 'sensor_names') and dec_airnow.sensor_names is not None:\n",
    "    sensor_names = dec_airnow.sensor_names\n",
    "else:\n",
    "    sensor_names = [\n",
    "        \"North Holywood\", \n",
    "        \"Los Angeles - N. Main Street\", \n",
    "        \"Compton\",\n",
    "        \"Crestline - Lake Gregory\",\n",
    "        \"Fontana - Arrow Highway\",\n",
    "        \"Glendora - Laurel\",\n",
    "        \"Lake Elsinore - W. Flint Street\",\n",
    "        \"Long Beach Signal Hill\",\n",
    "        \"Mira Loma - Van Buren\",\n",
    "        \"Reseda\",\n",
    "        \"Riverside - Rubidoux\",\n",
    "        \"Santa Clarita\",\n",
    "        \"Simi Valley - Cochran Street\",\n",
    "        \"Temecula (Lake Skinner)\"\n",
    "    ]\n",
    "\n",
    "print(\"\\n1. Plotting prediction comparison...\")\n",
    "plot_prediction_comparison(y_pred, y_test, sensor_names, sample_idx=8)\n",
    "\n",
    "print(\"\\n2. Plotting scatter comparison...\")\n",
    "plot_scatter_comparison(y_pred, y_test)\n",
    "\n",
    "print(\"\\n3. Plotting error by sensor...\")\n",
    "plot_error_by_sensor(y_pred, y_test, sensor_names)\n",
    "\n",
    "print(\"\\n4. Plotting time series comparison...\")\n",
    "plot_time_series_comparison(y_pred, y_test, sensor_names)\n",
    "    \n",
    "print(\"\\n5. Plotting time series with shifted predictions...\")\n",
    "plot_time_series_comparison(y_pred, y_test, sensor_names, shift_pred=1)\n",
    "\n",
    "print(\"\\n6. Printing metrics...\")\n",
    "print_metrics(y_pred, y_test, sensor_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save_exp_results",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save experiment comparison\n",
    "with open(os.path.join(output_dir, 'experiment1_results.txt'), 'w') as f:\n",
    "    f.write(\"==== Experiment 1 Results ====\\n\")\n",
    "    f.write(f\"Experiment 1 (No-fire December, two weeks): MAE = {exp1_results['mae']:.4f}, RMSE = {exp1_results['rmse']:.4f}, R² = {exp1_results['r2']:.4f}\\n\")\n",
    "    f.write(f\"\\nAnalysis completed on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "print(\"\\nExperiment 1 complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hysplitrevised",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
